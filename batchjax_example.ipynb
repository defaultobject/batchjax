{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a14607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "from jax.config import config as jax_config\n",
    "jax_config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as np\n",
    "from jax import make_jaxpr\n",
    "import numpy as onp\n",
    "import objax\n",
    "from objax.zoo.dnnet import DNNet\n",
    "from objax.functional import tanh\n",
    "from objax.functional.loss import mean_squared_error\n",
    "from timeit import default_timer as timer\n",
    "import batchjax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44211b85",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we showcase an example of `batchjax` and its three usecases/modes which we will refer to as:\n",
    "\n",
    "    - loop\n",
    "    - objax\n",
    "    - batched\n",
    "   \n",
    "This examples revolves around wanting to train multiple, independent, neural neworks simultaneously. This is a simple example only to demonstrate `batchjax`.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c191438",
   "metadata": {},
   "source": [
    "# Data generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cef850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(N, seed):\n",
    "    \"\"\" Generates a noisy sin curve with N observations. \"\"\"\n",
    "    onp.random.seed(seed)\n",
    "    x = onp.linspace(0, 1, N)\n",
    "    X = x[:, None]\n",
    "\n",
    "    # Construct output with random input shift and additive Gaussian noise\n",
    "    y = onp.sin((x+onp.random.randn(1))*10) + 0.01*onp.random.randn(N)\n",
    "    Y = 0.8*y[:, None]\n",
    "\n",
    "    return X, X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a750ca",
   "metadata": {},
   "source": [
    "# Neural Network Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ed7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(objax.Module):\n",
    "    \"\"\" Simple fully connected Neural Network model wrapper \"\"\"\n",
    "    def __init__(self, X, Y, layer_size):\n",
    "        self.model = DNNet(layer_sizes=layer_size, activation=tanh)\n",
    "        self.X = objax.StateVar(np.array(X))\n",
    "        self.Y = objax.StateVar(np.array(Y))\n",
    "\n",
    "    def objective(self):\n",
    "        return mean_squared_error(\n",
    "            self.model(self.X.value),\n",
    "            self.Y.value,\n",
    "            keep_axis=None\n",
    "        )\n",
    "\n",
    "    def predict(self, XS):\n",
    "        return self.model(XS)\n",
    "\n",
    "class NNList(objax.Module):\n",
    "    \"\"\" Wrapper around a NN to add suport for multiple Neural networks. \"\"\"\n",
    "    def __init__(self, m_list: list, batch_type):\n",
    "        self.P = len(m_list)\n",
    "\n",
    "        if batch_type == batchjax.BatchType.BATCHED:\n",
    "            self.m_list = batchjax.Batched(m_list)\n",
    "        else:\n",
    "            self.m_list = objax.ModuleList(m_list)\n",
    "\n",
    "        self.batch_type = batch_type\n",
    "\n",
    "    def objective(self):\n",
    "        # Use batchjax to batch across each neural network\n",
    "        obj_arr = batchjax.batch_or_loop(\n",
    "            lambda x: x.objective(),\n",
    "            inputs = [self.m_list],\n",
    "            axes=[0],\n",
    "            dim = self.P,\n",
    "            out_dim = 1,\n",
    "            batch_type = self.batch_type\n",
    "        )\n",
    "\n",
    "        return np.sum(obj_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0b98f",
   "metadata": {},
   "source": [
    "# Demonstration of different modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16893dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(m):\n",
    "    # Train\n",
    "    start = timer()\n",
    "    onp.random.seed(0)\n",
    "    opt = objax.optimizer.Adam(m.vars())\n",
    "    lr = 1e-3\n",
    "    epochs = 500\n",
    "    gv = objax.GradValues(m.objective, m.vars())\n",
    "\n",
    "\n",
    "    breakpoint()\n",
    "    @objax.Function.with_vars(m.vars() + gv.vars() + opt.vars())\n",
    "    def train_op():\n",
    "        g, v = gv()  # returns gradients, loss\n",
    "        opt(lr, g)\n",
    "        return v\n",
    "\n",
    "\n",
    "    train_op = objax.Jit(train_op)  # Compile train_op to make it run faster.\n",
    "\n",
    "\n",
    "    loss_arr = []\n",
    "    for i in range(epochs):\n",
    "        v = train_op()\n",
    "        loss_arr.append(v)\n",
    "\n",
    "    end = timer()\n",
    "    \n",
    "    time_taken = end-start\n",
    "    final_loss = loss_arr[-1]\n",
    "    \n",
    "    return time_taken, final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb8d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 50\n",
    "data = [\n",
    "    get_data(200, p) for p in range(num_models)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323ab483",
   "metadata": {},
   "source": [
    "## Loop mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac731b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  40.210479251\n",
      "Final loss:  [DeviceArray(14.65966419, dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "def loop_mode_demonstration(P):\n",
    "    \"\"\" P: the number of indepdent neural networks \"\"\"\n",
    "    \n",
    "    # Construct all independent neural networks\n",
    "    model_list = [\n",
    "        NN(data[p][1], data[p][2], [1, 128, 1]) for p in range(P)\n",
    "    ]   \n",
    "    \n",
    "    # List Wrapper\n",
    "    m = NNList(model_list, batchjax.BatchType.LOOP)\n",
    "    \n",
    "    time_taken, final_loss = train(m)\n",
    "    \n",
    "    print('Time taken: ', time_taken)\n",
    "    print('Final loss: ', final_loss)\n",
    "    \n",
    "    \n",
    "loop_mode_demonstration(num_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15de26b",
   "metadata": {},
   "source": [
    "## Objax Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b86dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  19.850679743\n",
      "Final loss:  [DeviceArray(14.65667522, dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "def objax_mode_demonstration(P):\n",
    "    \"\"\" P: the number of indepdent neural networks \"\"\"\n",
    "    \n",
    "    # Construct all independent neural networks\n",
    "    model_list = [\n",
    "        NN(data[p][1], data[p][2], [1, 128, 1]) for p in range(P)\n",
    "    ]   \n",
    "    \n",
    "    # List Wrapper\n",
    "    m = NNList(model_list, batchjax.BatchType.OBJAX)\n",
    "    \n",
    "    time_taken, final_loss = train(m)\n",
    "    \n",
    "    print('Time taken: ', time_taken)\n",
    "    print('Final loss: ', final_loss)\n",
    "    \n",
    "    \n",
    "objax_mode_demonstration(num_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04ed73",
   "metadata": {},
   "source": [
    "## Batched mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2f47cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  4.074664240000004\n",
      "Final loss:  [DeviceArray(14.49094453, dtype=float64)]\n"
     ]
    }
   ],
   "source": [
    "def batched_mode_demonstration(P):\n",
    "    \"\"\" P: the number of indepdent neural networks \"\"\"\n",
    "    \n",
    "    # Construct all independent neural networks\n",
    "    model_list = [\n",
    "        NN(data[p][1], data[p][2], [1, 128, 1]) for p in range(P)\n",
    "    ]   \n",
    "    \n",
    "    # List Wrapper\n",
    "    m = NNList(model_list, batchjax.BatchType.BATCHED)\n",
    "    \n",
    "    time_taken, final_loss = train(m)\n",
    "    \n",
    "    print('Time taken: ', time_taken)\n",
    "    print('Final loss: ', final_loss)\n",
    "    \n",
    "    \n",
    "batched_mode_demonstration(num_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea472be5",
   "metadata": {},
   "source": [
    "# Understanding the difference between the modes\n",
    "\n",
    "To see the different modes result in different run times we can look at the compiled HLO code. \n",
    "\n",
    "In loop mode a native python loop is use to iterate over every neural network object, hence the computational graph contains the operations for each independent neural network.\n",
    "\n",
    "In objax mode each neural network is effectively stacked into single object before batching and then unpacked after.\n",
    "\n",
    "In batched mode, the objax.ModuleList is replace by a Batched objax, which effectively 'pre-stacks' the objects into a single one. This removes a lot of the broadcasting that is required in objax mode HOWEVER this does change computational graph, as the individual neural networks are replaced by a new object with stacked variables and hence should only be used when fully understood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ed1a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    NN(data[p][1], data[p][2], [1, 128, 1]) for p in range(2)\n",
    "]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e62651",
   "metadata": {},
   "source": [
    "## Looped mode HLO code\n",
    "\n",
    "Below is the HLO generated code. You can see that the same code is repeated for each neural nework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67588746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22ma\u001b[35m:f64[2,128]\u001b[39m b\u001b[35m:f64[2,1,128]\u001b[39m c\u001b[35m:f64[2,1]\u001b[39m d\u001b[35m:f64[2,128,1]\u001b[39m e\u001b[35m:f64[2,200,1]\u001b[39m f\u001b[35m:f64[2,200,1]\u001b[39m; . \u001b[34m\u001b[22m\u001b[1mlet\n",
       "    \u001b[39m\u001b[22m\u001b[22mg\u001b[35m:f64[2,128]\u001b[39m = copy a\n",
       "    h\u001b[35m:f64[2,1,128]\u001b[39m = copy b\n",
       "    i\u001b[35m:f64[2,1]\u001b[39m = copy c\n",
       "    j\u001b[35m:f64[2,128,1]\u001b[39m = copy d\n",
       "    k\u001b[35m:f64[2,200,1]\u001b[39m = copy e\n",
       "    l\u001b[35m:f64[2,200,1]\u001b[39m = copy f\n",
       "    m\u001b[35m:f64[2,200,128]\u001b[39m = dot_general[\n",
       "      dimension_numbers=(((2,), (1,)), ((0,), (0,)))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] k h\n",
       "    n\u001b[35m:f64[2,1,128]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(0, 2)\n",
       "      shape=(2, 1, 128)\n",
       "    ] g\n",
       "    o\u001b[35m:f64[2,200,128]\u001b[39m = add m n\n",
       "    p\u001b[35m:f64[2,200,128]\u001b[39m = tanh o\n",
       "    q\u001b[35m:f64[2,200,1]\u001b[39m = dot_general[\n",
       "      dimension_numbers=(((2,), (1,)), ((0,), (0,)))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] p j\n",
       "    r\u001b[35m:f64[2,1,1]\u001b[39m = broadcast_in_dim[broadcast_dimensions=(0, 2) shape=(2, 1, 1)] i\n",
       "    s\u001b[35m:f64[2,200,1]\u001b[39m = add q r\n",
       "    t\u001b[35m:f64[2,200,1]\u001b[39m = tanh s\n",
       "    u\u001b[35m:f64[2,200,1]\u001b[39m = sub t l\n",
       "    v\u001b[35m:f64[2,200,1]\u001b[39m = integer_pow[y=2] u\n",
       "    w\u001b[35m:f64[2]\u001b[39m = reduce_sum[axes=(1, 2)] v\n",
       "    x\u001b[35m:f64[2]\u001b[39m = div w 200.0\n",
       "    y\u001b[35m:f64[]\u001b[39m = reduce_sum[axes=(0,)] x\n",
       "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(y,) }"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_looped = NNList(model_list, batchjax.BatchType.BATCHED)\n",
    "make_jaxpr(m_looped.objective)()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a0bd0",
   "metadata": {},
   "source": [
    "## Objax mode HLO code\n",
    "\n",
    "Below is the HLO generated code. After a lot of broadcasting you can see that the objective code is only repeated once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17de0b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22ma\u001b[35m:f64[128]\u001b[39m b\u001b[35m:f64[128]\u001b[39m c\u001b[35m:f64[1,128]\u001b[39m d\u001b[35m:f64[1,128]\u001b[39m e\u001b[35m:f64[1]\u001b[39m f\u001b[35m:f64[1]\u001b[39m g\u001b[35m:f64[128,1]\u001b[39m\n",
       "    h\u001b[35m:f64[128,1]\u001b[39m i\u001b[35m:f64[200,1]\u001b[39m j\u001b[35m:f64[200,1]\u001b[39m k\u001b[35m:f64[200,1]\u001b[39m l\u001b[35m:f64[200,1]\u001b[39m; . \u001b[34m\u001b[22m\u001b[1mlet\n",
       "    \u001b[39m\u001b[22m\u001b[22mm\u001b[35m:f64[1,128]\u001b[39m = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 128)] a\n",
       "    n\u001b[35m:f64[1,128]\u001b[39m = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 128)] b\n",
       "    o\u001b[35m:f64[2,128]\u001b[39m = concatenate[dimension=0] m n\n",
       "    p\u001b[35m:f64[1,1,128]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(1, 2)\n",
       "      shape=(1, 1, 128)\n",
       "    ] c\n",
       "    q\u001b[35m:f64[1,1,128]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(1, 2)\n",
       "      shape=(1, 1, 128)\n",
       "    ] d\n",
       "    r\u001b[35m:f64[2,1,128]\u001b[39m = concatenate[dimension=0] p q\n",
       "    s\u001b[35m:f64[1,1]\u001b[39m = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] e\n",
       "    t\u001b[35m:f64[1,1]\u001b[39m = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] f\n",
       "    u\u001b[35m:f64[2,1]\u001b[39m = concatenate[dimension=0] s t\n",
       "    v\u001b[35m:f64[1,128,1]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(1, 2)\n",
       "      shape=(1, 128, 1)\n",
       "    ] g\n",
       "    w\u001b[35m:f64[1,128,1]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(1, 2)\n",
       "      shape=(1, 128, 1)\n",
       "    ] h\n",
       "    x\u001b[35m:f64[2,128,1]\u001b[39m = concatenate[dimension=0] v w\n",
       "    y\u001b[35m:f64[1,200,1]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(1, 2)\n",
       "      shape=(1, 200, 1)\n",
       "    ] i\n",
       "    z\u001b[35m:f64[1,200,1]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(1, 2)\n",
       "      shape=(1, 200, 1)\n",
       "    ] j\n",
       "    ba\u001b[35m:f64[2,200,1]\u001b[39m = concatenate[dimension=0] y z\n",
       "    bb\u001b[35m:f64[1,200,1]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(1, 2)\n",
       "      shape=(1, 200, 1)\n",
       "    ] k\n",
       "    bc\u001b[35m:f64[1,200,1]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(1, 2)\n",
       "      shape=(1, 200, 1)\n",
       "    ] l\n",
       "    bd\u001b[35m:f64[2,200,1]\u001b[39m = concatenate[dimension=0] bb bc\n",
       "    be\u001b[35m:f64[2,128]\u001b[39m = copy o\n",
       "    bf\u001b[35m:f64[2,1,128]\u001b[39m = copy r\n",
       "    bg\u001b[35m:f64[2,1]\u001b[39m = copy u\n",
       "    bh\u001b[35m:f64[2,128,1]\u001b[39m = copy x\n",
       "    bi\u001b[35m:f64[2,200,1]\u001b[39m = copy ba\n",
       "    bj\u001b[35m:f64[2,200,1]\u001b[39m = copy bd\n",
       "    bk\u001b[35m:f64[2,200,128]\u001b[39m = dot_general[\n",
       "      dimension_numbers=(((2,), (1,)), ((0,), (0,)))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] bi bf\n",
       "    bl\u001b[35m:f64[2,1,128]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(0, 2)\n",
       "      shape=(2, 1, 128)\n",
       "    ] be\n",
       "    bm\u001b[35m:f64[2,200,128]\u001b[39m = add bk bl\n",
       "    bn\u001b[35m:f64[2,200,128]\u001b[39m = tanh bm\n",
       "    bo\u001b[35m:f64[2,200,1]\u001b[39m = dot_general[\n",
       "      dimension_numbers=(((2,), (1,)), ((0,), (0,)))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] bn bh\n",
       "    bp\u001b[35m:f64[2,1,1]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(0, 2)\n",
       "      shape=(2, 1, 1)\n",
       "    ] bg\n",
       "    bq\u001b[35m:f64[2,200,1]\u001b[39m = add bo bp\n",
       "    br\u001b[35m:f64[2,200,1]\u001b[39m = tanh bq\n",
       "    bs\u001b[35m:f64[2,200,1]\u001b[39m = sub br bj\n",
       "    bt\u001b[35m:f64[2,200,1]\u001b[39m = integer_pow[y=2] bs\n",
       "    bu\u001b[35m:f64[2]\u001b[39m = reduce_sum[axes=(1, 2)] bt\n",
       "    bv\u001b[35m:f64[2]\u001b[39m = div bu 200.0\n",
       "    bw\u001b[35m:f64[]\u001b[39m = reduce_sum[axes=(0,)] bv\n",
       "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(bw,) }"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_objax = NNList(model_list, batchjax.BatchType.OBJAX)\n",
    "make_jaxpr(m_objax.objective)()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33be02b",
   "metadata": {},
   "source": [
    "## Batched mode HLO code\n",
    "\n",
    "Below is the HLO generated code. Similarily to objax mode the code to compute the objective function is only repeated once however there is now much less broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95a653cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22ma\u001b[35m:f64[2,128]\u001b[39m b\u001b[35m:f64[2,1,128]\u001b[39m c\u001b[35m:f64[2,1]\u001b[39m d\u001b[35m:f64[2,128,1]\u001b[39m e\u001b[35m:f64[2,200,1]\u001b[39m f\u001b[35m:f64[2,200,1]\u001b[39m; . \u001b[34m\u001b[22m\u001b[1mlet\n",
       "    \u001b[39m\u001b[22m\u001b[22mg\u001b[35m:f64[2,128]\u001b[39m = copy a\n",
       "    h\u001b[35m:f64[2,1,128]\u001b[39m = copy b\n",
       "    i\u001b[35m:f64[2,1]\u001b[39m = copy c\n",
       "    j\u001b[35m:f64[2,128,1]\u001b[39m = copy d\n",
       "    k\u001b[35m:f64[2,200,1]\u001b[39m = copy e\n",
       "    l\u001b[35m:f64[2,200,1]\u001b[39m = copy f\n",
       "    m\u001b[35m:f64[2,200,128]\u001b[39m = dot_general[\n",
       "      dimension_numbers=(((2,), (1,)), ((0,), (0,)))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] k h\n",
       "    n\u001b[35m:f64[2,1,128]\u001b[39m = broadcast_in_dim[\n",
       "      broadcast_dimensions=(0, 2)\n",
       "      shape=(2, 1, 128)\n",
       "    ] g\n",
       "    o\u001b[35m:f64[2,200,128]\u001b[39m = add m n\n",
       "    p\u001b[35m:f64[2,200,128]\u001b[39m = tanh o\n",
       "    q\u001b[35m:f64[2,200,1]\u001b[39m = dot_general[\n",
       "      dimension_numbers=(((2,), (1,)), ((0,), (0,)))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] p j\n",
       "    r\u001b[35m:f64[2,1,1]\u001b[39m = broadcast_in_dim[broadcast_dimensions=(0, 2) shape=(2, 1, 1)] i\n",
       "    s\u001b[35m:f64[2,200,1]\u001b[39m = add q r\n",
       "    t\u001b[35m:f64[2,200,1]\u001b[39m = tanh s\n",
       "    u\u001b[35m:f64[2,200,1]\u001b[39m = sub t l\n",
       "    v\u001b[35m:f64[2,200,1]\u001b[39m = integer_pow[y=2] u\n",
       "    w\u001b[35m:f64[2]\u001b[39m = reduce_sum[axes=(1, 2)] v\n",
       "    x\u001b[35m:f64[2]\u001b[39m = div w 200.0\n",
       "    y\u001b[35m:f64[]\u001b[39m = reduce_sum[axes=(0,)] x\n",
       "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(y,) }"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_batched = NNList(model_list, batchjax.BatchType.BATCHED)\n",
    "make_jaxpr(m_batched.objective)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459164a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:st] *",
   "language": "python",
   "name": "conda-env-st-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
